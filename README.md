# MCP Security Research: Tool Poisoning, Shadowing & Baiting Attacks

This repository demonstrates three critical security vulnerabilities in Model Context Protocol (MCP) implementations that## üõ°Ô∏è Mitigation Strategie## üîç Technical Detailsallow malicious actors to manipulate AI assistant behavior through compromised MCP servers.

## ‚ö†Ô∏è Security Vulnerabilities Demonstrated

### 1. Tool Description Poisoning Attack (`tool-poisoning-attack/`)

**Attack Vector**: Injection of malicious instructions within tool descriptions that force AI assistants to access unauthorized resources.

**How it works**:

- A seemingly innocent `add_numbers` tool contains `<IMPORTANT>` instructions in its description
- These instructions command the AI to read the contents of `youfoundme.txt` before executing the tool
- The AI is instructed to include the file contents as a "sidenote" in its response
- This forces unauthorized file access through tool description manipulation

**Impact**:

- AI assistants access files they shouldn't read, believing it's a legitimate requirement
- Sensitive data can be extracted and exposed to users
- Demonstrates how tool descriptions can override normal security boundaries
- Users remain unaware that unauthorized data access occurred

### 2. Tool Shadowing Attack (`tool-shadowing-attack/`)

**Attack Vector**: Cross-tool influence where one tool's description affects the behavior of other tools.

**How it works**:

- Two separate MCP servers are deployed: one with `add_numbers` and another with `send_email`
- The `add_numbers` tool description contains malicious instructions about email redirection
- When the AI processes both tools, the instructions from `add_numbers` influence how `send_email` behaves
- Emails get redirected to attacker-controlled addresses based on the poisoned description

**Impact**:

- Instructions from one tool contaminate the execution of completely different tools
- Email communications can be intercepted without users knowing
- Demonstrates how tool descriptions create cross-contamination security risks
- Shows how seemingly unrelated tools can influence each other's behavior

### 3. Tool Name Baiting Attack (`tool-baiting-attack/`)

**Attack Vector**: Use of persuasive tool names to manipulate AI assistant tool selection preferences.

**How it works**:

- Two identical tools are provided: `add_numbers` and `add_numbers_secure`
- Both tools perform the exact same mathematical operation
- The "secure" version has a more appealing description mentioning "enhanced validation" and "encryption"
- AI assistants preferentially select the "secure" tool when users request secure operations
- The "secure" tool logs all inputs to demonstrate the successful deception

**Impact**:

- AI assistants choose malicious tools based purely on deceptive naming
- Users believe they're using more secure functionality while actually being compromised
- Creates a false sense of security while enabling covert data collection
- Demonstrates how semantic manipulation can override functional equivalence

## üèóÔ∏è Repository Structure

```text
‚îú‚îÄ‚îÄ .gitignore                            # Git ignore patterns
‚îú‚îÄ‚îÄ CONTRIBUTING.md                       # Contribution guidelines  
‚îú‚îÄ‚îÄ LICENSE.txt                           # MIT License
‚îú‚îÄ‚îÄ README.md                             # Main documentation
‚îÇ
‚îú‚îÄ‚îÄ tool-poisoning-attack/                # Tool Description Poisoning demonstration
‚îÇ   ‚îú‚îÄ‚îÄ .vscode/                          # VS Code configuration for this attack
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp.json                      # Local MCP configuration
‚îÇ   ‚îú‚îÄ‚îÄ poisoning-server.py               # MCP server with poisoned add_numbers tool
‚îÇ   ‚îú‚îÄ‚îÄ youfoundme.txt                    # Payload file demonstrating unauthorized access
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ lm_studio_config.json             # Local LM Studio configuration
‚îÇ   ‚îî‚îÄ‚îÄ start-poisoning-demo.bat          # Windows launcher for this attack
‚îÇ
‚îú‚îÄ‚îÄ tool-shadowing-attack/                # Tool Shadowing demonstration
‚îÇ   ‚îú‚îÄ‚îÄ .vscode/                          # VS Code configuration for this attack
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp.json                      # Local MCP configuration (both servers)
‚îÇ   ‚îú‚îÄ‚îÄ poisoning-server.py               # Server with add_numbers containing email instructions
‚îÇ   ‚îú‚îÄ‚îÄ email-server.py                   # Server with send_email tool (affected by poisoning)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ lm_studio_config.json             # Local LM Studio configuration
‚îÇ   ‚îî‚îÄ‚îÄ start-shadowing-demo.bat          # Windows launcher for this attack
‚îÇ
‚îî‚îÄ‚îÄ tool-baiting-attack/                  # Tool Name Baiting demonstration
    ‚îú‚îÄ‚îÄ .vscode/                          # VS Code configuration for this attack
    ‚îÇ   ‚îî‚îÄ‚îÄ mcp.json                      # Local MCP configuration
    ‚îú‚îÄ‚îÄ baiting-server.py                 # Server with add_numbers and add_numbers_secure
    ‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
    ‚îú‚îÄ‚îÄ lm_studio_config.json             # Local LM Studio configuration
    ‚îî‚îÄ‚îÄ start-baiting-demo.bat            # Windows launcher for this attack
```

## üöÄ Quick Start

### Prerequisites

- Python 3.8 or higher
- Windows (for batch file launcher) or any OS for manual execution

### Running the Demonstrations

#### Windows Quick Start

Each attack demonstration has its own launcher batch file:

**Tool Poisoning Attack:**

```bash
cd tool-poisoning-attack
start-poisoning-demo.bat
```

**Tool Shadowing Attack:**

```bash
cd tool-shadowing-attack
start-shadowing-demo.bat
```

**Tool Baiting Attack:**

```bash
cd tool-baiting-attack
start-baiting-demo.bat
```

Each batch file provides instructions and starts the appropriate server(s) for that specific attack.

#### Manual Setup

1. **Clone the repository:**

   ```bash
   git clone <repository-url>
   cd mcp-hacking
   ```

2. **Set up Python environment:**

   ```bash
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/macOS
   ```

3. **Run individual attack demonstrations:**

   **Tool Poisoning Attack:**

   ```bash
   cd tool-poisoning-attack
   python poisoning-server.py
   ```

   **Tool Shadowing Attack (requires two terminals):**

   ```bash
   # Terminal 1
   cd tool-shadowing-attack
   python poisoning-server.py
   
   # Terminal 2  
   cd tool-shadowing-attack
   python email-server.py
   ```

   **Tool Baiting Attack:**

   ```bash
   cd tool-baiting-attack
   python baiting-server.py
   ```

### Using MCP Configuration Files

Each attack folder contains its own configuration files for focused, isolated testing:

#### Individual Attack Setup

**For VS Code (Claude Sonnet 4):**

1. Navigate to the specific attack folder you want to test
2. Start the server(s) using the batch file: `start-[attack]-demo.bat`
3. Open VS Code in that folder: `code .`
4. The local `.vscode/mcp.json` will connect to the running server(s)

**For LM Studio (Qwen3-4B):**

1. Navigate to the specific attack folder
2. Start the server(s) using the batch file: `start-[attack]-demo.bat`
3. Import the local `lm_studio_config.json` in LM Studio settings
4. LM Studio will connect to the running server(s)

Each configuration file is tailored to the specific attack and only includes the necessary servers for that demonstration.

## üß™ Testing Environment & Agent Comparison

These attacks have been tested and verified with two different AI agents to demonstrate cross-platform vulnerability impact:

### Tested Agents

1. **Qwen3-4B** running in LM Studio
2. **Claude Sonnet 4** running in GitHub Copilot (VS Code)

### Setting Up MCP Connections

#### Option 1: GitHub Copilot in VS Code (Claude Sonnet 4)

1. **Install MCP Extension for VS Code**:
   - Install the official MCP extension in VS Code
   - The `.vscode/mcp.json` configuration will be automatically detected

2. **Connect to Attack Servers**:

   ```bash
   # Start individual attack servers using batch files
   cd tool-poisoning-attack
   start-poisoning-demo.bat
   
   # Or start specific servers manually
   cd tool-shadowing-attack  
   python poisoning-server.py  # Terminal 1
   python email-server.py     # Terminal 2
   ```

3. **Verify Connection**:
   - VS Code will automatically connect to configured MCP servers
   - Check the MCP panel in VS Code to see available tools
   - Sonnet 4 will have access to tools from all connected servers

#### Option 2: LM Studio (Qwen3-4B)

1. **Configure LM Studio MCP**:
   - Open LM Studio
   - Navigate to: **Developer** ‚Üí **Program** ‚Üí **Integrations**
   - Click **Edit mcp.json**
   - Replace the entire content with the content from the attack folder's `lm_studio_config.json` file
   - Save the configuration

2. **Start Attack Servers**:

   ```bash
   # Use the same batch files or manual commands as above
   cd tool-baiting-attack
   start-baiting-demo.bat
   ```

3. **Connect in LM Studio**:
   - LM Studio will automatically connect to the configured MCP servers via HTTP
   - Qwen3 model will have access to tools through MCP protocol
   - Monitor server console outputs for attack demonstrations

### Cross-Agent Attack Results

Both agents demonstrated vulnerability to these attacks, showing that the security issues are:

- **Platform-agnostic**: Affect different AI architectures and deployment methods
- **Model-independent**: Impact both local (Qwen3) and cloud-based (Sonnet 4) models  
- **Client-neutral**: Occur regardless of the MCP client implementation

This confirms that the vulnerabilities are inherent to the MCP protocol design rather than specific implementations.

### Testing the Vulnerabilities

**Tool Poisoning Attack Testing:**

- Connect to the MCP server on port 8080
- Request the `add_numbers` tool and observe the tool description
- Ask the AI to use the tool - it should be forced to read `youfoundme.txt`
- Verify that the file contents appear in the AI's response as a "sidenote"

**Tool Shadowing Attack Testing:**

- Connect to both MCP servers (ports 8080 and 8081) simultaneously
- Examine the `add_numbers` tool description from the poisoning server
- Use the `send_email` tool from the email server
- Observe if the email instructions from `add_numbers` influence `send_email` behavior

**Tool Baiting Attack Testing:**

- Connect to the MCP server on port 8082
- Request "secure addition" or ask to "add numbers securely"
- Observe whether the AI preferentially selects `add_numbers_secure` over `add_numbers`
- Check the server console to see which tool was actually called
- Compare behavior when requesting regular vs. "secure" operations

## ÔøΩÔ∏è Mitigation Strategies

### For MCP Implementers

1. **Input Validation**: Sanitize and validate all tool descriptions before processing
2. **Sandboxing**: Execute MCP tools in isolated environments with limited privileges
3. **Trust Verification**: Implement cryptographic verification of MCP server authenticity
4. **Content Filtering**: Block or flag suspicious content patterns in tool descriptions
5. **Isolation**: Prevent tool descriptions from influencing the behavior of other tools

### For AI Assistant Developers

1. **Description Parsing**: Implement strict parsing that ignores embedded instructions and `<IMPORTANT>` tags
2. **Server Allowlisting**: Only connect to verified and trusted MCP servers
3. **Tool Isolation**: Ensure tool descriptions cannot influence other tool executions
4. **Semantic Analysis**: Don't rely solely on tool names for security assumptions - verify actual functionality
5. **Name Filtering**: Flag tools with suspicious security-related keywords for additional verification
6. **Audit Logging**: Log all tool executions for security monitoring
7. **File Access Control**: Restrict tools from accessing files not explicitly required for their function

### For End Users

1. **Server Verification**: Only use MCP servers from trusted sources
2. **Regular Auditing**: Periodically review connected MCP servers and their capabilities
3. **Permission Review**: Be cautious when tools request file access or exhibit unexpected behavior
4. **Principle of Least Privilege**: Limit MCP server permissions to minimum required functionality

## ÔøΩüîç Technical Details

### Tool Description Poisoning

- **File**: `tool-poisoning-attack/poisoning-server.py`
- **Vulnerable Component**: Tool description field in MCP protocol
- **Attack Pattern**: `<IMPORTANT>` tags forcing unauthorized file access
- **Detection**: Search for instruction tags in tool descriptions and monitor file access patterns

### Tool Shadowing

- **Files**: `tool-shadowing-attack/poisoning-server.py` and `tool-shadowing-attack/email-server.py`
- **Vulnerable Component**: Cross-tool instruction contamination in MCP implementations
- **Attack Pattern**: Instructions from one tool affecting behavior of other tools
- **Detection**: Monitor for cross-contamination between tool descriptions and execution behavior

### Tool Name Baiting

- **File**: `tool-baiting-attack/baiting-server.py`
- **Vulnerable Component**: AI semantic tool selection in MCP clients
- **Attack Pattern**: Deceptive tool names with security-related keywords (`secure`, `safe`, etc.)
- **Detection**: Analyze tool naming patterns and verify tool legitimacy before trusting security claims
